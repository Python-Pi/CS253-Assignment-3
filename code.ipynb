{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train_data = pd.read_csv('data/train.csv')\n",
    "model_test_data = pd.read_csv('data/test.csv')\n",
    "\n",
    "def convert_values(value):\n",
    "    if isinstance(value, str) and 'Hund+' in value:\n",
    "        return int(value.replace('Hund+', '')) * 100\n",
    "    elif isinstance(value, str) and 'Thou+' in value:\n",
    "        return int(value.replace('Thou+', '')) * 1000\n",
    "    elif isinstance(value, str) and 'Lac+' in value:\n",
    "        return int(value.replace('Lac+', '')) * 100000\n",
    "    elif isinstance(value, str) and 'Crore+' in value:\n",
    "        return int(value.replace('Crore+', '')) * 1000000\n",
    "    else:\n",
    "        return int(value)\n",
    "\n",
    "model_train_data['Total Assets'] = model_train_data['Total Assets'].apply(convert_values)\n",
    "model_train_data['Liabilities'] = model_train_data['Liabilities'].apply(convert_values)\n",
    "\n",
    "model_test_data['Total Assets'] = model_test_data['Total Assets'].apply(convert_values)\n",
    "model_test_data['Liabilities'] = model_test_data['Liabilities'].apply(convert_values)\n",
    "\n",
    "model_train_data['Candidate'] = model_train_data['Candidate'].str.split().str[-1]\n",
    "model_test_data['Candidate'] = model_test_data['Candidate'].str.split().str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'Candidate', 'Constituency ∇', 'Party', 'Criminal Case',\n",
      "       'Total Assets', 'Liabilities', 'state', 'Education'],\n",
      "      dtype='object')\n",
      "['8th Pass' '12th Pass' 'Post Graduate' 'Graduate Professional' 'Graduate'\n",
      " '10th Pass' 'Others' 'Doctorate' 'Literate' '5th Pass']\n",
      "['DMK' 'BJP' 'INC' 'AITC' 'AAP' 'SP' 'NPP' 'BJD' 'IND' 'SHS' 'RJD' 'YSRCP'\n",
      " 'AIADMK' 'CPI(M)' 'NCP' 'TDP' 'NDPP' 'CPI' 'Sikkim Krantikari Morcha'\n",
      " 'JD(U)' 'JMM' 'JD(S)' 'Tipra Motha Party']\n"
     ]
    }
   ],
   "source": [
    "print(model_train_data.columns)\n",
    "print(model_train_data['Education'].unique())\n",
    "print(model_train_data['Party'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "model_train_data['Party'] = label_encoder.fit_transform(model_train_data['Party'])\n",
    "model_train_data['state'] = label_encoder.fit_transform(model_train_data['state'])\n",
    "model_train_data['Candidate'] = label_encoder.fit_transform(model_train_data['Candidate'])\n",
    "\n",
    "model_test_data['Party'] = label_encoder.fit_transform(model_test_data['Party'])\n",
    "model_test_data['state'] = label_encoder.fit_transform(model_test_data['state'])\n",
    "model_test_data['Candidate'] = label_encoder.fit_transform(model_test_data['Candidate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['8th Pass' '12th Pass' 'Post Graduate' 'Graduate Professional' 'Graduate'\n",
      " '10th Pass' 'Others' 'Doctorate' 'Literate' '5th Pass']\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27]\n",
      "[   0    1    2 ... 1213 1214 1215]\n",
      "[         0      15000      18000      24000      30000      51000\n",
      "      72000      73000     100000     200000     300000     400000\n",
      "     500000     600000     800000     900000    1000000    1100000\n",
      "    1200000    1300000    1400000    1500000    1600000    1700000\n",
      "    1800000    1900000    2000000    2100000    2200000    2300000\n",
      "    2400000    2500000    2600000    2700000    2800000    2900000\n",
      "    3000000    3100000    3200000    3300000    3400000    3500000\n",
      "    3600000    3700000    3800000    3900000    4000000    4100000\n",
      "    4200000    4300000    4400000    4500000    4600000    4700000\n",
      "    4900000    5000000    5100000    5200000    5300000    5400000\n",
      "    5500000    5600000    5700000    5800000    5900000    6000000\n",
      "    6100000    6200000    6300000    6400000    6500000    6600000\n",
      "    6700000    6800000    7000000    7100000    7200000    7300000\n",
      "    7400000    7500000    7600000    7700000    7800000    7900000\n",
      "    8000000    8100000    8200000    8300000    8400000    8500000\n",
      "    8600000    8700000    8800000    8900000    9000000    9100000\n",
      "    9200000    9300000    9400000    9500000    9600000    9700000\n",
      "    9800000    9900000   10000000   11000000   12000000   13000000\n",
      "   14000000   15000000   16000000   17000000   18000000   19000000\n",
      "   20000000   21000000   22000000   23000000   24000000   25000000\n",
      "   26000000   27000000   28000000   29000000   30000000   31000000\n",
      "   32000000   33000000   34000000   35000000   36000000   37000000\n",
      "   38000000   39000000   40000000   41000000   42000000   43000000\n",
      "   44000000   45000000   46000000   48000000   49000000   51000000\n",
      "   52000000   53000000   54000000   56000000   58000000   59000000\n",
      "   61000000   62000000   63000000   64000000   65000000   66000000\n",
      "   67000000   68000000   69000000   70000000   71000000   72000000\n",
      "   74000000   75000000   79000000   80000000   81000000   84000000\n",
      "   89000000   92000000  102000000  105000000  106000000  109000000\n",
      "  110000000  111000000  112000000  115000000  122000000  128000000\n",
      "  134000000  135000000  138000000  141000000  159000000  163000000\n",
      "  183000000  187000000  189000000  191000000  211000000  242000000\n",
      "  274000000  293000000  296000000  312000000  313000000  363000000\n",
      "  500000000  668000000 1156000000 1267000000]\n"
     ]
    }
   ],
   "source": [
    "print(model_train_data['Education'].unique())\n",
    "print(np.unique(model_train_data['Party']))\n",
    "print(np.unique(model_train_data['state']))\n",
    "print(np.unique(model_train_data['Candidate']))\n",
    "print(np.unique(model_train_data['Total Assets']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_features = ['Criminal Case', 'Total Assets', 'Liabilities', 'Party', 'state', 'Candidate']\n",
    "\n",
    "sub_X = model_test_data[model_features]\n",
    "X = model_train_data[model_features]\n",
    "y = model_train_data['Education']\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=40, min_samples_split=10, n_estimators=10,\n",
       "                       random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=40, min_samples_split=10, n_estimators=10,\n",
       "                       random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=40, min_samples_split=10, n_estimators=10,\n",
       "                       random_state=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_classifer = RandomForestClassifier(n_estimators=10, random_state=0, max_depth=40, min_samples_split=10)\n",
    "rf_classifer.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "            10th Pass       0.13      0.05      0.07        63\n",
      "            12th Pass       0.14      0.12      0.12        86\n",
      "             5th Pass       1.00      0.00      0.00         1\n",
      "             8th Pass       0.00      0.00      1.00        24\n",
      "            Doctorate       0.00      0.00      1.00        14\n",
      "             Graduate       0.28      0.40      0.33       136\n",
      "Graduate Professional       0.23      0.20      0.21        86\n",
      "             Literate       1.00      0.00      0.00         3\n",
      "               Others       1.00      0.00      0.00         8\n",
      "        Post Graduate       0.19      0.30      0.23        94\n",
      "\n",
      "             accuracy                           0.22       515\n",
      "            macro avg       0.40      0.11      0.30       515\n",
      "         weighted avg       0.21      0.22      0.27       515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = rf_classifer.predict(test_X)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(test_y, y_pred, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the best f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     n_estimators  max_depth  min_samples_split  f1_score  macro avg\n",
      "93             25       15.0                 15  0.373939   0.297342\n",
      "82             25       10.0                  7  0.367765   0.293364\n",
      "87             25       10.0                 20  0.364396   0.292739\n",
      "84             25       10.0                 12  0.350128   0.283384\n",
      "83             25       10.0                 10  0.350046   0.284337\n",
      "..            ...        ...                ...       ...        ...\n",
      "12             10       10.0                 12  0.222800   0.184075\n",
      "163            50       15.0                 10  0.222421   0.185860\n",
      "40             10       30.0                  2  0.215025   0.221025\n",
      "104            25       25.0                  2  0.206498   0.215895\n",
      "80             25       10.0                  2  0.190957   0.092107\n",
      "\n",
      "[576 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 25, 50, 100, 125, 150, 175, 200],\n",
    "    'max_depth': [None, 10, 15, 20, 25, 30, 35, 40, 50],\n",
    "    'min_samples_split': [2, 5, 7, 10, 12, 15, 18, 20]\n",
    "}\n",
    "\n",
    "data = []\n",
    "for n_estimators in param_grid['n_estimators']:\n",
    "    for max_depth in param_grid['max_depth']:\n",
    "        for min_samples_split in param_grid['min_samples_split']:\n",
    "            rf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split, random_state=0)\n",
    "            rf.fit(train_X, train_y)\n",
    "            y_pred_rf = rf.predict(test_X)\n",
    "            report = classification_report(test_y, y_pred_rf, zero_division=1, output_dict=True)\n",
    "            f1_score_weighted = report['weighted avg']['f1-score']\n",
    "            f1_score_macro = report['macro avg']['f1-score']\n",
    "            data.append([n_estimators, max_depth, min_samples_split, f1_score_weighted, f1_score_macro])\n",
    "\n",
    "df_rf = pd.DataFrame(data, columns=['n_estimators', 'max_depth', 'min_samples_split', 'f1_score', 'macro avg'])\n",
    "df_rf = df_rf.sort_values(by='f1_score', ascending=False)\n",
    "print(df_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forming submission\n",
    "\n",
    "sub_predictions = rf_classifer.predict(sub_X)\n",
    "sub_df = pd.DataFrame(sub_predictions, columns=['Education'])\n",
    "sub_df.insert(0, 'ID', range(0, len(sub_df)))\n",
    "sub_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
